{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ__d_petycW"
      },
      "outputs": [],
      "source": [
        "#@title **1. Setup**\n",
        "\n",
        "#@markdown ### Identification\n",
        "huggingface_username = \"Synthyra\"  #@param {type:\"string\"}\n",
        "huggingface_token = \"\"            #@param {type:\"string\"}\n",
        "wandb_api_key = \"\"                #@param {type:\"string\"}\n",
        "synthyra_api_key = \"\"             #@param {type:\"string\"}\n",
        "github_token = \"\"                 #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "github_clone_path = f\"https://{github_token}@github.com/Synthyra/ProbePackageHolder.git\"\n",
        "# !git clone {github_clone_path}\n",
        "# !cd ProbePackageHolder\n",
        "# !pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import argparse\n",
        "from types import SimpleNamespace\n",
        "from base_models.get_base_models import BaseModelArguments, standard_benchmark\n",
        "from data.hf_data import HFDataArguments\n",
        "from data.supported_datasets import supported_datasets, standard_data_benchmark\n",
        "from embedder import EmbeddingArguments\n",
        "from probes.get_probe import ProbeArguments\n",
        "from probes.trainers import TrainerArguments\n",
        "from main import MainProcess\n",
        "\n",
        "\n",
        "main = MainProcess(argparse.Namespace(), GUI=True)\n",
        "\n",
        "#@markdown **Paths**\n",
        "log_dir = \"logs\"                            #@param {type:\"string\"}\n",
        "results_dir = \"results\"                    #@param {type:\"string\"}\n",
        "model_save_dir = \"weights\"                 #@param {type:\"string\"}\n",
        "embedding_save_dir = \"embeddings\"          #@param {type:\"string\"}\n",
        "download_dir = \"Synthyra/mean_pooled_embeddings\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "main.full_args.hf_token = huggingface_token\n",
        "main.full_args.wandb_api_key = wandb_api_key\n",
        "main.full_args.synthyra_api_key = synthyra_api_key\n",
        "main.full_args.log_dir = log_dir\n",
        "main.full_args.results_dir = results_dir\n",
        "main.full_args.model_save_dir = model_save_dir\n",
        "main.full_args.embedding_save_dir = embedding_save_dir\n",
        "main.full_args.download_dir = download_dir\n",
        "main.full_args.replay_path = None\n",
        "main.logger_args = SimpleNamespace(**main.full_args.__dict__)\n",
        "main.start_log_gui()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to setup the session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFgNDvDAt0xp"
      },
      "outputs": [],
      "source": [
        "#@title **2. Data Settings**\n",
        "\n",
        "max_length = 1024          #@param {type:\"integer\"}\n",
        "trim = False               #@param {type:\"boolean\"}\n",
        "#@markdown Enter comma-separated dataset names from `supported_datasets`.\n",
        "#@markdown If left empty, the code uses `standard_data_benchmark`.\n",
        "dataset_names = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "data_paths = [supported_datasets[name.strip()] for name in dataset_names.split(\",\") if name.strip()]\n",
        "\n",
        "main.data_paths = data_paths\n",
        "main.max_length = max_length\n",
        "main.trim = trim\n",
        "main.data_args = HFDataArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main.get_datasets()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to load datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHCDeczNt20y"
      },
      "outputs": [],
      "source": [
        "#@title **3. Embedding Settings**\n",
        "\n",
        "batch_size = 4                #@param {type:\"integer\"}\n",
        "num_workers = 0               #@param {type:\"integer\"}\n",
        "download_embeddings = False   #@param {type:\"boolean\"}\n",
        "matrix_embed = False          #@param {type:\"boolean\"}\n",
        "#@markdown Comma-separated pooling types: e.g. `mean,cls`\n",
        "embedding_pooling_types = \"mean\"  #@param {type:\"string\"}\n",
        "embed_dtype = \"float32\"       #@param [\"float32\",\"float16\",\"bfloat16\",\"float8_e4m3fn\",\"float8_e5m2\"]\n",
        "sql = False                   #@param {type:\"boolean\"}\n",
        "\n",
        "main.full_args.all_seqs = main.all_seqs\n",
        "main.batch_size = batch_size\n",
        "main.num_workers = num_workers\n",
        "main.download_embeddings = download_embeddings\n",
        "main.matrix_embed = matrix_embed\n",
        "main.embedding_pooling_types = [p.strip() for p in embedding_pooling_types.split(\",\") if p.strip()]\n",
        "if embed_dtype == \"float32\": main.embed_dtype = torch.float32\n",
        "elif embed_dtype == \"float16\": main.embed_dtype = torch.float16\n",
        "elif embed_dtype == \"bfloat16\": main.embed_dtype = torch.bfloat16   \n",
        "elif embed_dtype == \"float8_e4m3fn\": main.embed_dtype = torch.float8_e4m3fn\n",
        "elif embed_dtype == \"float8_e5m2\": main.embed_dtype = torch.float8_e5m2\n",
        "else:\n",
        "    print(f\"Invalid embedding dtype: {embed_dtype}. Using float32.\")\n",
        "    main.embed_dtype = torch.float32\n",
        "main.sql = sql\n",
        "\n",
        "\n",
        "main.embedding_args = EmbeddingArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main.save_embeddings_to_disk()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to embed sequences:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1iMWkLzt8QM"
      },
      "outputs": [],
      "source": [
        "#@title **4. Model Selection**\n",
        "\n",
        "#@markdown Comma-separated model names.\n",
        "#@markdown If empty, defaults to `standard_benchmark`.\n",
        "model_names = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "def select_models():\n",
        "    selected = [m.strip() for m in model_names.split(\",\") if m.strip()]\n",
        "    if not selected:\n",
        "        selected = standard_benchmark\n",
        "\n",
        "    full_args = argparse.Namespace(\n",
        "        model_names=selected,\n",
        "        # other args\n",
        "    )\n",
        "    model_args = BaseModelArguments(**vars(full_args))\n",
        "    print(\"Selected model(s):\", selected)\n",
        "    print(\"Model Args:\", model_args)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to choose models:\n",
        "select_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7R-Htvit9Ti"
      },
      "outputs": [],
      "source": [
        "#@title **5. Probe Settings**\n",
        "\n",
        "probe_type = \"linear\"     #@param [\"linear\", \"transformer\", \"crossconv\"]\n",
        "tokenwise = False         #@param {type:\"boolean\"}\n",
        "pre_ln = True             #@param {type:\"boolean\"}\n",
        "n_layers = 1              #@param {type:\"integer\"}\n",
        "hidden_dim = 8192         #@param {type:\"integer\"}\n",
        "dropout = 0.2             #@param {type:\"number\"}\n",
        "\n",
        "classifier_dim = 4096     #@param {type:\"integer\"}\n",
        "classifier_dropout = 0.2  #@param {type:\"number\"}\n",
        "n_heads = 4               #@param {type:\"integer\"}\n",
        "rotary = True             #@param {type:\"boolean\"}\n",
        "probe_pooling_types_str = \"mean, cls\"  #@param {type:\"string\"}\n",
        "\n",
        "def create_probe_args():\n",
        "    probe_pooling_types = [p.strip() for p in probe_pooling_types_str.split(\",\") if p.strip()]\n",
        "\n",
        "    full_args = argparse.Namespace(\n",
        "        probe_type=probe_type,\n",
        "        tokenwise=tokenwise,\n",
        "        pre_ln=pre_ln,\n",
        "        n_layers=n_layers,\n",
        "        hidden_dim=hidden_dim,\n",
        "        dropout=dropout,\n",
        "        classifier_dim=classifier_dim,\n",
        "        classifier_dropout=classifier_dropout,\n",
        "        n_heads=n_heads,\n",
        "        rotary=rotary,\n",
        "        probe_pooling_types=probe_pooling_types,\n",
        "        # other relevant fields ...\n",
        "    )\n",
        "    probe_args = ProbeArguments(**vars(full_args))\n",
        "    print(\"Probe Arguments:\", probe_args)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to configure the probe:\n",
        "create_probe_args()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W4OYnn4uIyU"
      },
      "outputs": [],
      "source": [
        "#@title **6. Training Settings**\n",
        "\n",
        "use_lora = False               #@param {type:\"boolean\"}\n",
        "hybrid_probe = False           #@param {type:\"boolean\"}\n",
        "full_finetuning = False        #@param {type:\"boolean\"}\n",
        "\n",
        "num_epochs = 200               #@param {type:\"integer\"}\n",
        "trainer_batch_size = 64        #@param {type:\"integer\"}\n",
        "gradient_accumulation_steps = 1  #@param {type:\"integer\"}\n",
        "lr = 0.0001                    #@param {type:\"number\"}\n",
        "weight_decay = 0.0             #@param {type:\"number\"}\n",
        "patience = 3                   #@param {type:\"integer\"}\n",
        "\n",
        "def run_trainer():\n",
        "    full_args = argparse.Namespace(\n",
        "        use_lora=use_lora,\n",
        "        hybrid_probe=hybrid_probe,\n",
        "        full_finetuning=full_finetuning,\n",
        "        num_epochs=num_epochs,\n",
        "        trainer_batch_size=trainer_batch_size,\n",
        "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "        patience=patience\n",
        "        # ...\n",
        "    )\n",
        "    trainer_args = TrainerArguments(**vars(full_args))\n",
        "    print(\"Trainer Args:\", trainer_args)\n",
        "\n",
        "    # Example: run your training code\n",
        "    mp = MainProcess(full_args)\n",
        "\n",
        "    if use_lora:\n",
        "        print(\"Running LoRA training... (not implemented in example)\")\n",
        "    elif full_finetuning:\n",
        "        print(\"Running full finetuning... (not implemented in example)\")\n",
        "    elif hybrid_probe:\n",
        "        print(\"Running hybrid probe training... (not implemented in example)\")\n",
        "    else:\n",
        "        print(\"Running default probe training...\")\n",
        "        mp.run_probes()\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to run the trainer:\n",
        "run_trainer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdAk8wxWuJWO"
      },
      "outputs": [],
      "source": [
        "#@title **7. Log Replay**\n",
        "\n",
        "replay_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "def start_replay():\n",
        "    if not replay_path:\n",
        "        print(\"No replay path provided.\")\n",
        "        return\n",
        "\n",
        "    from logger import LogReplayer\n",
        "    replayer = LogReplayer(replay_path)\n",
        "    replay_args = replayer.parse_log()\n",
        "    # Then do something with replay_args\n",
        "    print(\"Replaying from:\", replay_path)\n",
        "    replayer.run_replay(None)  # Or pass your main object, etc.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press to replay logs:\n",
        "start_replay()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
