{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OUT OF DATE - NEEDS TO BE UPDATED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mQ__d_petycW"
      },
      "outputs": [],
      "source": [
        "#@title **1. Setup**\n",
        "\n",
        "#@markdown ### Identification\n",
        "huggingface_username = \"Synthyra\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "huggingface_token = \"\"            #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "wandb_api_key = \"\"                #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "synthyra_api_key = \"\"             #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "github_token = \"\"                 #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "github_clone_path = f\"https://{github_token}@github.com/Synthyra/ProbePackageHolder.git\"\n",
        "# !git clone {github_clone_path}\n",
        "# %cd ProbePackageHolder\n",
        "# !pip install -r requirements.txt --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title **2. Session/Directory Settings**\n",
        "\n",
        "import torch\n",
        "import argparse\n",
        "from types import SimpleNamespace\n",
        "from base_models.get_base_models import BaseModelArguments, standard_benchmark\n",
        "from data.hf_data import HFDataArguments\n",
        "from data.supported_datasets import supported_datasets\n",
        "from embedder import EmbeddingArguments\n",
        "from probes.get_probe import ProbeArguments\n",
        "from probes.trainers import TrainerArguments\n",
        "from main import MainProcess\n",
        "\n",
        "\n",
        "main = MainProcess(argparse.Namespace(), GUI=True)\n",
        "\n",
        "#@markdown **Paths**\n",
        "\n",
        "#@markdown These will be created automatically if they don't exist\n",
        "\n",
        "#@markdown **Log Directory**\n",
        "log_dir = \"logs\"                            #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Results Directory**\n",
        "results_dir = \"results\"                    #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Model Save Directory**\n",
        "model_save_dir = \"weights\"                 #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Embedding Save Directory**\n",
        "embedding_save_dir = \"embeddings\"          #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Download Directory**\n",
        "#@markdown - Where embeddings are downloaded on Hugging Face\n",
        "download_dir = \"Synthyra/mean_pooled_embeddings\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "main.full_args.hf_token = huggingface_token\n",
        "main.full_args.wandb_api_key = wandb_api_key\n",
        "main.full_args.synthyra_api_key = synthyra_api_key\n",
        "main.full_args.log_dir = log_dir\n",
        "main.full_args.results_dir = results_dir\n",
        "main.full_args.model_save_dir = model_save_dir\n",
        "main.full_args.embedding_save_dir = embedding_save_dir\n",
        "main.full_args.download_dir = download_dir\n",
        "main.full_args.replay_path = None\n",
        "main.logger_args = SimpleNamespace(**main.full_args.__dict__)\n",
        "main.start_log_gui()\n",
        "\n",
        "#@markdown Press play to setup the session:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFgNDvDAt0xp"
      },
      "outputs": [],
      "source": [
        "#@title **2. Data Settings**\n",
        "\n",
        "#@markdown **Max Sequence Length**\n",
        "max_length = 2048          #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Trim Sequences**\n",
        "#@markdown - If true, sequences are removed if they are longer than the maximum length\n",
        "#@markdown - If false, sequences are truncated to the maximum length\n",
        "trim = False               #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Dataset Names**\n",
        "#@markdown Valid options (comma-separated):\n",
        "\n",
        "#@markdown *Multi-label classification:*\n",
        "\n",
        "#@markdown - EC, GO-CC, GO-BP, GO-MF\n",
        "\n",
        "#@markdown *Single-label classification:*\n",
        "\n",
        "#@markdown - MB, DeepLoc-2, DeepLoc-10, solubility, localization, material-production, cloning-clf, number-of-folds\n",
        "\n",
        "#@markdown *Regression:*\n",
        "\n",
        "#@markdown - enzyme-kcat,temperature-stability, optimal-temperature, optimal-ph, fitness-prediction, stability-prediction, fluorescence-prediction\n",
        "\n",
        "#@markdown *PPI:*\n",
        "\n",
        "#@markdown - human-ppi, peptide-HLA-MHC-affinity\n",
        "\n",
        "#@markdown *Tokenwise:*\n",
        "\n",
        "#@markdown - SecondaryStructure-3, SecondaryStructure-8\n",
        "dataset_names = \"EC, DeepLoc-2, DeepLoc-10, enzyme-kcat\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "data_paths = [supported_datasets[name.strip()] for name in dataset_names.split(\",\") if name.strip()]\n",
        "\n",
        "main.full_args.data_paths = data_paths\n",
        "main.full_args.max_length = max_length\n",
        "main.full_args.trim = trim\n",
        "main.data_args = HFDataArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main.get_datasets()\n",
        "\n",
        "#@markdown Press play to load datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D1iMWkLzt8QM"
      },
      "outputs": [],
      "source": [
        "#@title **3. Model Selection**\n",
        "\n",
        "#@markdown Comma-separated model names.\n",
        "#@markdown If empty, defaults to `standard_benchmark`.\n",
        "#@markdown Valid options (comma-separated):\n",
        "#@markdown - `ESM2-8, ESM2-35, ESM2-150, ESM2-650`\n",
        "#@markdown - `ESMC-300, ESMC-600`\n",
        "#@markdown - `Random, Random-Transformer`\n",
        "model_names = \"ESMC-300\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "selected_models = [name.strip() for name in model_names.split(\",\") if name.strip()]\n",
        "\n",
        "if not selected_models:\n",
        "    selected_models = standard_benchmark\n",
        "\n",
        "main.full_args.model_names = selected_models\n",
        "main.model_args = BaseModelArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main._write_args()\n",
        "\n",
        "#@markdown *Press play to choose models:*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHCDeczNt20y"
      },
      "outputs": [],
      "source": [
        "#@title **4. Embedding Settings**\n",
        "#@markdown **Batch size**\n",
        "batch_size = 4                #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Number of dataloader workers**\n",
        "#@markdown - We recommend 0 for small sets of sequences, but 4-8 for larger sets\n",
        "num_workers = 0               #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Download embeddings from Hugging Face**\n",
        "#@markdown - If there is a precomputed embedding type that's useful to you, it is probably faster to download it\n",
        "#@markdown - HIGHLY recommended for CPU users\n",
        "download_embeddings = False   #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Full residue embeddings**\n",
        "#@markdown - If true, embeddings are saved as a matrix of shape `(L, d)`\n",
        "#@markdown - If false, embeddings are pooled to `(d,)`\n",
        "matrix_embed = False          #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Embedding Pooling Types**\n",
        "#@markdown - If more than one is passed, embeddings are concatenated\n",
        "#@markdown Valid options (comma-separated):\n",
        "#@markdown - `mean, max, norm, median, std, var, cls, parti`\n",
        "#@markdown - `parti` (pool parti) must be used on its own\n",
        "embedding_pooling_types = \"mean, std\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Embedding Data Type**\n",
        "#@markdown - Embeddings are cast to this data type for storage\n",
        "embed_dtype = \"float32\"       #@param [\"float32\",\"float16\",\"bfloat16\",\"float8_e4m3fn\",\"float8_e5m2\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Save embeddings to SQLite**\n",
        "#@markdown - If true, embeddings are saved to a SQLite database\n",
        "#@markdown - They will be accessed on the fly by the trainer\n",
        "#@markdown - This is HIGHLY recommended for matrix embeddings\n",
        "#@markdown - If false, embeddings are saved to a .pth file but loaded all at once\n",
        "sql = False                   #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "main.full_args.all_seqs = main.all_seqs\n",
        "main.full_args.batch_size = batch_size\n",
        "main.full_args.num_workers = num_workers\n",
        "main.full_args.download_embeddings = download_embeddings\n",
        "main.full_args.matrix_embed = matrix_embed\n",
        "main.full_args.embedding_pooling_types = [p.strip() for p in embedding_pooling_types.split(\",\") if p.strip()]\n",
        "if embed_dtype == \"float32\": main.embed_dtype = torch.float32\n",
        "elif embed_dtype == \"float16\": main.embed_dtype = torch.float16\n",
        "elif embed_dtype == \"bfloat16\": main.embed_dtype = torch.bfloat16   \n",
        "elif embed_dtype == \"float8_e4m3fn\": main.embed_dtype = torch.float8_e4m3fn\n",
        "elif embed_dtype == \"float8_e5m2\": main.embed_dtype = torch.float8_e5m2\n",
        "else:\n",
        "    print(f\"Invalid embedding dtype: {embed_dtype}. Using float32.\")\n",
        "    main.embed_dtype = torch.float32\n",
        "main.sql = sql\n",
        "\n",
        "\n",
        "main.embedding_args = EmbeddingArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main.save_embeddings_to_disk()\n",
        "\n",
        "#@markdown *Press play to embed sequences:*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "K7R-Htvit9Ti"
      },
      "outputs": [],
      "source": [
        "#@title **5. Probe Settings**\n",
        "\n",
        "#@markdown **Probe Type**\n",
        "#@markdown - `linear`: a MLP for pooled embeddings\n",
        "#@markdown - `transformer`: a transformer model for matrix embeddings\n",
        "#@markdown - `retrievalnet`: custom combination of cross-attention and convolution for matrix embeddings\n",
        "probe_type = \"linear\"     #@param [\"linear\", \"transformer\", \"retrievalnet\"]\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Tokenwise**\n",
        "#@markdown - If true, the objective is to predict a property of each token (matrix embeddings only)\n",
        "#@markdown - If false, the objective is to predict a property of the entire sequence (pooled embeddings OR matrix embeddings)\n",
        "tokenwise = False         #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Pre-LayerNorm**\n",
        "#@markdown - If true, a LayerNorm is applied as the first layer of the probe the probe\n",
        "#@markdown - Typicall improves performance\n",
        "pre_ln = True             #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Number of layers**\n",
        "#@markdown - Number of hidden layers in the probe\n",
        "#@markdown - Linear probes have 1 input layer and 2 output layers, so 1 layer is a 4 layer MLP\n",
        "#@markdown - This refers to how many transformer blocks are used in the transformer probe\n",
        "#@markdown - Same for retrievalnet probes\n",
        "n_layers = 1              #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Hidden dimension**\n",
        "#@markdown - The hidden dimension of the model\n",
        "#@markdown - 2048 - 8192 is recommended for linear probes, 384 - 1536 is recommended for transformer probes\n",
        "hidden_dim = 8192         #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Dropout**\n",
        "#@markdown - Dropout rate for the probe\n",
        "#@markdown - 0.2 is recommended for linear, 0.1 otherwise\n",
        "dropout = 0.2             #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Classifier dimension**\n",
        "#@markdown - The dimension of the classifier layer (transformer, retrievalnet probes only)\n",
        "classifier_dim = 4096     #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Classifier Dropout**\n",
        "#@markdown - Dropout rate for the classifier layer\n",
        "classifier_dropout = 0.2  #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Number of heads**\n",
        "#@markdown - Number of attention heads in models with attention\n",
        "#@markdown - between `hidden_dim // 128` and `hidden_dim // 32` is recommended\n",
        "n_heads = 4               #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Rotary Embeddings**\n",
        "#@markdown - If true, rotary embeddings are used with attention layers\n",
        "rotary = True             #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Probe Pooling Types**\n",
        "#@markdown - If more than one is passed, embeddings are concatenated\n",
        "#@markdown Valid options (comma-separated):\n",
        "#@markdown - `mean, max, norm, median, std, var, cls`\n",
        "#@markdown - Is how the transformer or retrievalnet embeddings are pooled for sequence-wise tasks\n",
        "probe_pooling_types_str = \"mean, cls\"  #@param {type:\"string\"}\n",
        "\n",
        "probe_pooling_types = [p.strip() for p in probe_pooling_types_str.split(\",\") if p.strip()]\n",
        "\n",
        "main.full_args.probe_type = probe_type\n",
        "main.full_args.tokenwise = tokenwise\n",
        "main.full_args.pre_ln = pre_ln\n",
        "main.full_args.n_layers = n_layers\n",
        "main.full_args.hidden_dim = hidden_dim\n",
        "main.full_args.dropout = dropout\n",
        "main.full_args.classifier_dim = classifier_dim\n",
        "main.full_args.classifier_dropout = classifier_dropout\n",
        "main.full_args.n_heads = n_heads\n",
        "main.full_args.rotary = rotary\n",
        "main.full_args.probe_pooling_types = probe_pooling_types\n",
        "\n",
        "main.probe_args = ProbeArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main._write_args()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to configure the probe:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8W4OYnn4uIyU"
      },
      "outputs": [],
      "source": [
        "#@title **6. Training Settings**\n",
        "\n",
        "#@markdown **Use LoRA**\n",
        "#@markdown - If true, LoRA on the base model\n",
        "use_lora = False               #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Hybrid Probe**\n",
        "#@markdown - If true, the probe is trained on frozen embeddings\n",
        "#@markdown - Then, the base model is finetuned alongside the probe\n",
        "hybrid_probe = False           #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Full Finetuning**\n",
        "#@markdown - If true, the base model is finetuned for the task\n",
        "full_finetuning = False        #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Number of epochs**\n",
        "num_epochs = 200               #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Trainer Batch Size**\n",
        "#@markdown - The batch size for probe training\n",
        "#@markdown - We recommend between 32 and 256 with some combination of this and gradient accumulation steps\n",
        "trainer_batch_size = 64        #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Gradient Accumulation Steps**\n",
        "gradient_accumulation_steps = 1  #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Learning Rate**\n",
        "lr = 0.0001                    #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Weight Decay**\n",
        "#@markdown - If you are having issues with overfitting, try increasing this\n",
        "weight_decay = 0.0             #@param {type:\"number\"}\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Early Stopping Patience**\n",
        "#@markdown - We recommend keep the epcohs high and using this to gage convergence\n",
        "patience = 10                   #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "\n",
        "main.full_args.use_lora = use_lora\n",
        "main.full_args.hybrid_probe = hybrid_probe\n",
        "main.full_args.full_finetuning = full_finetuning\n",
        "main.full_args.num_epochs = num_epochs\n",
        "main.full_args.trainer_batch_size = trainer_batch_size\n",
        "main.full_args.gradient_accumulation_steps = gradient_accumulation_steps\n",
        "main.full_args.lr = lr\n",
        "main.full_args.weight_decay = weight_decay\n",
        "main.full_args.patience = patience\n",
        "\n",
        "main.trainer_args = TrainerArguments(**main.full_args.__dict__)\n",
        "args_dict = {k: v for k, v in main.full_args.__dict__.items() if k != 'all_seqs' and 'token' not in k.lower() and 'api' not in k.lower()}\n",
        "main.logger_args = SimpleNamespace(**args_dict)\n",
        "main._write_args()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press play to run the trainer:\n",
        "main.run_nn_probe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdAk8wxWuJWO"
      },
      "outputs": [],
      "source": [
        "#@title **7. Log Replay**\n",
        "\n",
        "#@markdown **Replay Path**\n",
        "#@markdown - Replay everything from a log by passing the path to the log file\n",
        "replay_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "\n",
        "from logger import LogReplayer\n",
        "replayer = LogReplayer(replay_path)\n",
        "replay_args = replayer.parse_log()\n",
        "replay_args.replay_path = replay_path\n",
        "\n",
        "for key, value in replay_args.__dict__.items():\n",
        "    if key in main.full_args.__dict__:\n",
        "        main.full_args[key] = value\n",
        "\n",
        "replayer.run_replay(main)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Press to replay logs:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
